{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84fee67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\conda\\envs\\tf\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "E:\\conda\\envs\\tf\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "E:\\conda\\envs\\tf\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os, fnmatch\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM, Dropout, \\\n",
    "    Lambda, Input, Multiply, Layer, Conv1D, Concatenate\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, CSVLogger, \\\n",
    "    EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import soundfile as sf\n",
    "from wavinfo import WavInfoReader\n",
    "from random import shuffle, seed\n",
    "import numpy as np\n",
    "from DTLN_model import DTLN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e4d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file='weights/DTLN_model.h5'\n",
    "numLayer=2\n",
    "numUnits = 128\n",
    "blockLen = 512\n",
    "block_shift = 128\n",
    "num_elements_first_core = 2 + numLayer * 3 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f0e79c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstantLayerNormalization(Layer):\n",
    "    '''\n",
    "    Class implementing instant layer normalization. It can also be called \n",
    "    channel-wise layer normalization and was proposed by \n",
    "    Luo & Mesgarani (https://arxiv.org/abs/1809.07454v2) \n",
    "    '''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        '''\n",
    "            Constructor\n",
    "        '''\n",
    "        super(InstantLayerNormalization, self).__init__(**kwargs)\n",
    "        self.epsilon = 1e-7 \n",
    "        self.gamma = None\n",
    "        self.beta = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        '''\n",
    "        Method to build the weights.\n",
    "        '''\n",
    "        shape = input_shape[-1:]\n",
    "        # initialize gamma\n",
    "        self.gamma = self.add_weight(shape=shape,\n",
    "                             initializer='ones',\n",
    "                             trainable=True,\n",
    "                             name='gamma')\n",
    "        # initialize beta\n",
    "        self.beta = self.add_weight(shape=shape,\n",
    "                             initializer='zeros',\n",
    "                             trainable=True,\n",
    "                             name='beta')\n",
    " \n",
    "\n",
    "    def call(self, inputs):\n",
    "        '''\n",
    "        Method to call the Layer. All processing is done here.\n",
    "        '''\n",
    "\n",
    "        # calculate mean of each frame\n",
    "        mean = tf.math.reduce_mean(inputs, axis=[-1], keepdims=True)\n",
    "        # calculate variance of each frame\n",
    "        variance = tf.math.reduce_mean(tf.math.square(inputs - mean), \n",
    "                                       axis=[-1], keepdims=True)\n",
    "        # calculate standard deviation\n",
    "        std = tf.math.sqrt(variance + self.epsilon)\n",
    "        # normalize each frame independently \n",
    "        outputs = (inputs - mean) / std\n",
    "        # scale with gamma\n",
    "        outputs = outputs * self.gamma\n",
    "        # add the bias beta\n",
    "        outputs = outputs + self.beta\n",
    "        # return output\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93dc8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTLN_model():\n",
    "    '''\n",
    "    Class to create and train the DTLN model\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "\n",
    "        # defining default cost function\n",
    "        self.cost_function = self.snr_cost\n",
    "        # empty property for the model\n",
    "        self.model = []\n",
    "        # defining default parameters\n",
    "        self.fs = 16000\n",
    "        self.batchsize = 32\n",
    "        self.len_samples = 4\n",
    "        self.activation = 'sigmoid'\n",
    "        self.numUnits = 128\n",
    "        self.numLayer = 2\n",
    "        self.blockLen = 512\n",
    "        self.block_shift = 128\n",
    "        self.dropout = 0.25\n",
    "        self.lr = 1e-3\n",
    "        self.max_epochs = 200\n",
    "        self.encoder_size = 256\n",
    "        self.eps = 1e-7\n",
    "        # reset all seeds to 42 to reduce invariance between training runs\n",
    "        os.environ['PYTHONHASHSEED']=str(42)\n",
    "        seed(42)\n",
    "        np.random.seed(42)\n",
    "        tf.random.set_seed(42)\n",
    "        # some line to correctly find some libraries in TF 2.x\n",
    "        physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "        if len(physical_devices) > 0:\n",
    "            for device in physical_devices:\n",
    "                tf.config.experimental.set_memory_growth(device, enable=True)\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def snr_cost(s_estimate, s_true):\n",
    "        '''\n",
    "        Static Method defining the cost function. \n",
    "        The negative signal to noise ratio is calculated here. The loss is \n",
    "        always calculated over the last dimension. \n",
    "        '''\n",
    "\n",
    "        # calculating the SNR\n",
    "        snr = tf.reduce_mean(tf.math.square(s_true), axis=-1, keepdims=True) / \\\n",
    "            (tf.reduce_mean(tf.math.square(s_true-s_estimate), axis=-1, keepdims=True)+1e-7)\n",
    "        # using some more lines, because TF has no log10\n",
    "        num = tf.math.log(snr) \n",
    "        denom = tf.math.log(tf.constant(10, dtype=num.dtype))\n",
    "        loss = -10*(num / (denom))\n",
    "        # returning the loss\n",
    "        return loss\n",
    "        \n",
    "\n",
    "    def lossWrapper(self):\n",
    "        '''\n",
    "        A wrapper function which returns the loss function. This is done to\n",
    "        to enable additional arguments to the loss function if necessary.\n",
    "        '''\n",
    "        def lossFunction(y_true,y_pred):\n",
    "            # calculating loss and squeezing single dimensions away\n",
    "            loss = tf.squeeze(self.cost_function(y_pred,y_true))\n",
    "            # calculate mean over batches\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            # return the loss\n",
    "            return loss\n",
    "        # returning the loss function as handle\n",
    "        return lossFunction\n",
    "    \n",
    "    \n",
    "\n",
    "    '''\n",
    "    In the following some helper layers are defined.\n",
    "    '''  \n",
    "    \n",
    "    def segment(self, x):\n",
    "        '''\n",
    "        Method for an STFT helper layer used with a Lambda layer. The layer\n",
    "        calculates the STFT on the last dimension and returns the magnitude and\n",
    "        phase of the STFT.\n",
    "        '''\n",
    "        \n",
    "        # creating frames from the continuous waveform\n",
    "        frames = tf.signal.frame(x, self.blockLen, self.block_shift)\n",
    "        \n",
    "        return frames\n",
    "\n",
    "    def tftLayer(self, x):\n",
    "        '''\n",
    "        Method for an STFT helper layer used with a Lambda layer. The layer\n",
    "        calculates the STFT on the last dimension and returns the magnitude and\n",
    "        phase of the STFT.\n",
    "        '''\n",
    "        \n",
    "        # calculating the fft over the time frames. rfft returns NFFT/2+1 bins.\n",
    "        stft_dat = tf.signal.rfft(x)\n",
    "        # calculating magnitude and phase from the complex signal\n",
    "        mag = tf.abs(stft_dat)\n",
    "        phase = tf.math.angle(stft_dat)\n",
    "        # returning magnitude and phase as list\n",
    "        return [mag, phase]\n",
    "    \n",
    "    def stftLayer(self, x):\n",
    "        '''\n",
    "        Method for an STFT helper layer used with a Lambda layer. The layer\n",
    "        calculates the STFT on the last dimension and returns the magnitude and\n",
    "        phase of the STFT.\n",
    "        '''\n",
    "        \n",
    "        # creating frames from the continuous waveform\n",
    "        frames = tf.signal.frame(x, self.blockLen, self.block_shift)\n",
    "        # calculating the fft over the time frames. rfft returns NFFT/2+1 bins.\n",
    "        stft_dat = tf.signal.rfft(frames)\n",
    "        # calculating magnitude and phase from the complex signal\n",
    "        mag = tf.abs(stft_dat)\n",
    "        phase = tf.math.angle(stft_dat)\n",
    "        # returning magnitude and phase as list\n",
    "        return [mag, phase]\n",
    "    \n",
    "    def fftLayer(self, x):\n",
    "        '''\n",
    "        Method for an fft helper layer used with a Lambda layer. The layer\n",
    "        calculates the rFFT on the last dimension and returns the magnitude and\n",
    "        phase of the STFT.\n",
    "        '''\n",
    "        \n",
    "        # expanding dimensions\n",
    "        frame = tf.expand_dims(x, axis=1)\n",
    "        # calculating the fft over the time frames. rfft returns NFFT/2+1 bins.\n",
    "        stft_dat = tf.signal.rfft(frame)\n",
    "        # calculating magnitude and phase from the complex signal\n",
    "        mag = tf.abs(stft_dat)\n",
    "        phase = tf.math.angle(stft_dat)\n",
    "        # returning magnitude and phase as list\n",
    "        return [mag, phase]\n",
    "\n",
    " \n",
    "        \n",
    "    def ifftLayer(self, x):\n",
    "        '''\n",
    "        Method for an inverse FFT layer used with an Lambda layer. This layer\n",
    "        calculates time domain frames from magnitude and phase information. \n",
    "        As input x a list with [mag,phase] is required.\n",
    "        '''\n",
    "        \n",
    "        # calculating the complex representation\n",
    "        s1_stft = (tf.cast(x[0], tf.complex64) * \n",
    "                    tf.exp( (1j * tf.cast(x[1], tf.complex64))))\n",
    "        # returning the time domain frames\n",
    "        return tf.signal.irfft(s1_stft)  \n",
    "    \n",
    "    \n",
    "    def overlapAddLayer(self, x):\n",
    "        '''\n",
    "        Method for an overlap and add helper layer used with a Lambda layer.\n",
    "        This layer reconstructs the waveform from a framed signal.\n",
    "        '''\n",
    "\n",
    "        # calculating and returning the reconstructed waveform\n",
    "        return tf.signal.overlap_and_add(x, self.block_shift)\n",
    "    \n",
    "        \n",
    "\n",
    "    def seperation_kernel(self, num_layer, mask_size, x, stateful=False):\n",
    "        '''\n",
    "        Method to create a separation kernel. \n",
    "        !! Important !!: Do not use this layer with a Lambda layer. If used with\n",
    "        a Lambda layer the gradients are updated correctly.\n",
    "\n",
    "        Inputs:\n",
    "            num_layer       Number of LSTM layers\n",
    "            mask_size       Output size of the mask and size of the Dense layer\n",
    "        '''\n",
    "\n",
    "        # creating num_layer number of LSTM layers\n",
    "        for idx in range(num_layer):\n",
    "            x = LSTM(self.numUnits, return_sequences=True, stateful=stateful)(x)\n",
    "            # using dropout between the LSTM layer for regularization \n",
    "            if idx<(num_layer-1):\n",
    "                x = Dropout(self.dropout)(x)\n",
    "        # creating the mask with a Dense and an Activation layer\n",
    "        mask = Dense(mask_size)(x)\n",
    "        mask = Activation(self.activation)(mask)\n",
    "        # returning the mask\n",
    "        return mask\n",
    "    \n",
    "    def seperation_kernel_with_states(self, num_layer, mask_size, x, \n",
    "                                      in_states):\n",
    "        '''\n",
    "        Method to create a separation kernel, which returns the LSTM states. \n",
    "        !! Important !!: Do not use this layer with a Lambda layer. If used with\n",
    "        a Lambda layer the gradients are updated correctly.\n",
    "\n",
    "        Inputs:\n",
    "            num_layer       Number of LSTM layers\n",
    "            mask_size       Output size of the mask and size of the Dense layer\n",
    "        '''\n",
    "        \n",
    "        states_h = []\n",
    "        states_c = []\n",
    "        # creating num_layer number of LSTM layers\n",
    "        for idx in range(num_layer):\n",
    "            in_state = [in_states[:,idx,:, 0], in_states[:,idx,:, 1]]\n",
    "            x, h_state, c_state = LSTM(self.numUnits, return_sequences=True, \n",
    "                     unroll=True, return_state=True)(x, initial_state=in_state)\n",
    "            # using dropout between the LSTM layer for regularization \n",
    "            if idx<(num_layer-1):\n",
    "                x = Dropout(self.dropout)(x)\n",
    "            states_h.append(h_state)\n",
    "            states_c.append(c_state)\n",
    "        # creating the mask with a Dense and an Activation layer\n",
    "        mask = Dense(mask_size)(x)\n",
    "        mask = Activation(self.activation)(mask)\n",
    "        out_states_h = tf.reshape(tf.stack(states_h, axis=0), \n",
    "                                  [1,num_layer,self.numUnits])\n",
    "        out_states_c = tf.reshape(tf.stack(states_c, axis=0), \n",
    "                                  [1,num_layer,self.numUnits])\n",
    "        out_states = tf.stack([out_states_h, out_states_c], axis=-1)\n",
    "        # returning the mask and states\n",
    "        return mask, out_states\n",
    "\n",
    "    def build_DTLN_model(self, norm_stft=False):\n",
    "        '''\n",
    "        Method to build and compile the DTLN model. The model takes time domain \n",
    "        batches of size (batchsize, len_in_samples) and returns enhanced clips \n",
    "        in the same dimensions. As optimizer for the Training process the Adam\n",
    "        optimizer with a gradient norm clipping of 3 is used. \n",
    "        The model contains two separation cores. The first has an STFT signal \n",
    "        transformation and the second a learned transformation based on 1D-Conv \n",
    "        layer. \n",
    "        '''\n",
    "        # input layer for time signal\n",
    "        \n",
    "        farend_dat = Input(batch_shape=(2, 64000))\n",
    "        nearend_dat = Input(batch_shape=(2, 64000))\n",
    "        \n",
    "        # calculate Segment\n",
    "        farend_frames = Lambda(self.segment)(farend_dat)\n",
    "        nearend_frames = Lambda(self.segment)(nearend_dat)\n",
    "        print('farend_frames:',farend_frames.shape)\n",
    "        print('nearend_frames:',nearend_frames.shape)\n",
    "        \n",
    "        # calculate STFT\n",
    "        farend_mag,farend_angle = Lambda(self.tftLayer)(farend_frames)\n",
    "        nearend_mag,nearend_angle = Lambda(self.tftLayer)(nearend_frames)\n",
    "        print('farend_mag:',farend_mag.shape)\n",
    "        print('nearend_mag:',nearend_mag.shape)\n",
    "        \n",
    "        # normalizing log magnitude stfts to get more robust against level variations\n",
    "\n",
    "        if norm_stft:\n",
    "            farend_mag_norm = InstantLayerNormalization()(tf.math.log(farend_mag + 1e-7))\n",
    "        else:\n",
    "            # behaviour like in the paper\n",
    "            farend_mag_norm = farend_mag\n",
    "        \n",
    "        if norm_stft:\n",
    "            nearend_mag_norm = InstantLayerNormalization()(tf.math.log(nearend_mag + 1e-7))\n",
    "        else:\n",
    "            # behaviour like in the paper\n",
    "            nearend = nearend_mag\n",
    "        \n",
    "        print('farend_mag_norm:',farend_mag_norm.shape)\n",
    "        print('nearend_mag_norm:',nearend_mag_norm.shape)\n",
    "        \n",
    "        spectra = Concatenate(axis=-1)([nearend_mag_norm,farend_mag_norm])\n",
    "        print('spectra:',spectra.shape)\n",
    "        \n",
    "        # predicting mask with separation kernel  \n",
    "        a\n",
    "        print('mask_1:',mask_1.shape)\n",
    "        \n",
    "        # multiply mask with magnitude\n",
    "        estimated_mag = Multiply()([nearend_mag, mask_1])\n",
    "        print('estimated_mag:',estimated_mag.shape)\n",
    "        \n",
    "        # transform frames back to time domain\n",
    "        estimated_frames_1 = Lambda(self.ifftLayer)([estimated_mag,nearend_angle])\n",
    "        print('estimated_frames_1:',estimated_frames_1.shape)\n",
    "        \n",
    "        # encode time domain frames to feature domain\n",
    "        encoded_frames = Conv1D(self.encoder_size,1,strides=1,use_bias=False)(estimated_frames_1)\n",
    "        encoded_frames_ = Conv1D(self.encoder_size,1,strides=1,use_bias=False)(farend_frames)\n",
    "        print('encoded_frames:',encoded_frames.shape)\n",
    "        print('encoded_frames_:',encoded_frames_.shape)\n",
    "        \n",
    "        # normalize the input to the separation kernel\n",
    "        encoded_frames_norm = InstantLayerNormalization()(encoded_frames)\n",
    "        encoded_frames_norm_ = InstantLayerNormalization()(encoded_frames_)\n",
    "        print('encoded_frames_norm:',encoded_frames_norm.shape)\n",
    "        print('encoded_frames_norm_:',encoded_frames_norm_.shape)\n",
    "        \n",
    "        feature = Concatenate(axis=-1)([encoded_frames_norm,encoded_frames_norm_])\n",
    "        print('feature:',feature.shape)\n",
    "        \n",
    "        # predict mask based on the normalized feature frames\n",
    "        mask_2 = self.seperation_kernel(self.numLayer, self.encoder_size, feature)\n",
    "        print('mask_2:',mask_2.shape)\n",
    "        \n",
    "        # multiply encoded frames with the mask\n",
    "        estimated = Multiply()([encoded_frames, mask_2]) \n",
    "        print('estimated:',estimated.shape)\n",
    "        \n",
    "        # decode the frames back to time domain\n",
    "        decoded_frames = Conv1D(self.blockLen, 1, padding='causal',use_bias=False)(estimated)\n",
    "        print('decoded_frames:',decoded_frames.shape)\n",
    "        \n",
    "        # create waveform with overlap and add procedure\n",
    "        estimated_sig = Lambda(self.overlapAddLayer)(decoded_frames)\n",
    "        print('estimated_sig:',estimated_sig.shape)\n",
    "\n",
    "        \n",
    "        # create the model\n",
    "        self.model = Model(inputs=[farend_dat,nearend_dat], outputs=estimated_sig)\n",
    "        # show the model summary\n",
    "        print(self.model.summary())\n",
    "    \n",
    "    def build_DTLN_model_stateful(self, norm_stft=False):\n",
    "        '''\n",
    "        Method to build stateful DTLN model for real time processing. The model \n",
    "        takes one time domain frame of size (1, blockLen) and one enhanced frame. \n",
    "         \n",
    "        '''\n",
    "        \n",
    "        # input layer for time signal\n",
    "        farend_dat = Input(batch_shape=(1, self.blockLen))\n",
    "        nearend_dat = Input(batch_shape=(1, self.blockLen))\n",
    "        \n",
    "        # calculate Segment\n",
    "        farend_frames = Lambda(self.segment)(farend_dat)\n",
    "        nearend_frames = Lambda(self.segment)(nearend_dat)\n",
    "        \n",
    "        # calculate STFT\n",
    "        farend_mag,farend_angle = Lambda(self.tftLayer)(farend_frames)\n",
    "        nearend_mag,nearend_angle = Lambda(self.tftLayer)(nearend_frames)\n",
    "        \n",
    "        # normalizing log magnitude stfts to get more robust against level variations\n",
    "\n",
    "        if norm_stft:\n",
    "            farend_mag_norm = InstantLayerNormalization()(tf.math.log(farend_mag + 1e-7))\n",
    "        else:\n",
    "            # behaviour like in the paper\n",
    "            farend_mag_norm = farend_mag\n",
    "        \n",
    "        if norm_stft:\n",
    "            nearend_mag_norm = InstantLayerNormalization()(tf.math.log(nearend_mag + 1e-7))\n",
    "        else:\n",
    "            # behaviour like in the paper\n",
    "            nearend_mag_norm = nearend_mag\n",
    "    \n",
    "        \n",
    "        spectra = Concatenate(axis=-1)([nearend_mag_norm,farend_mag_norm])\n",
    "        \n",
    "        # predicting mask with separation kernel  \n",
    "        mask_1 = self.seperation_kernel(self.numLayer, (self.blockLen//2+1), spectra)\n",
    "        \n",
    "        # multiply mask with magnitude\n",
    "        estimated_mag = Multiply()([nearend_mag, mask_1])\n",
    "        \n",
    "        # transform frames back to time domain\n",
    "        estimated_frames_1 = Lambda(self.ifftLayer)([estimated_mag,nearend_angle])\n",
    "        \n",
    "        # encode time domain frames to feature domain\n",
    "        encoded_frames = Conv1D(self.encoder_size,1,strides=1,use_bias=False)(estimated_frames_1)\n",
    "        encoded_frames_ = Conv1D(self.encoder_size,1,strides=1,use_bias=False)(farend_frames)\n",
    "        \n",
    "        # normalize the input to the separation kernel\n",
    "        encoded_frames_norm = InstantLayerNormalization()(encoded_frames)\n",
    "        encoded_frames_norm_ = InstantLayerNormalization()(encoded_frames_)\n",
    "        \n",
    "        feature = Concatenate(axis=-1)([encoded_frames_norm,encoded_frames_norm_])\n",
    "        \n",
    "        # predict mask based on the normalized feature frames\n",
    "        mask_2 = self.seperation_kernel(self.numLayer, self.encoder_size, feature)\n",
    "        \n",
    "        # multiply encoded frames with the mask\n",
    "        estimated = Multiply()([encoded_frames, mask_2]) \n",
    "        \n",
    "        # decode the frames back to time domain\n",
    "        decoded_frames = Conv1D(self.blockLen, 1, padding='causal',use_bias=False)(estimated)\n",
    "        \n",
    "        # create waveform with overlap and add procedure\n",
    "        estimated_sig = Lambda(self.overlapAddLayer)(decoded_frames)\n",
    "\n",
    "        \n",
    "        # create the model\n",
    "        self.model = Model(inputs=[farend_dat,nearend_dat], outputs=estimated_sig)\n",
    "        # show the model summary\n",
    "        print(self.model.summary())\n",
    "    \n",
    "    def create_tf_lite_model(self, weights_file, target_name, norm_stft,use_dynamic_range_quant=False):\n",
    "        '''\n",
    "        Method to create a tf lite model folder from a weights file. \n",
    "        The conversion creates two models, one for each separation core. \n",
    "        Tf lite does not support complex numbers yet. Some processing must be \n",
    "        done outside the model.\n",
    "        For further information and how real time processing can be \n",
    "        implemented see \"real_time_processing_tf_lite.py\".\n",
    "        \n",
    "        The conversion only works with TF 2.3.\n",
    "\n",
    "        '''\n",
    "        # check for type\n",
    "        if  norm_stft:\n",
    "            num_elements_first_core = 4 + self.numLayer * 3 + 2\n",
    "        else:\n",
    "            num_elements_first_core = self.numLayer * 3 + 2\n",
    "        # build model    \n",
    "        self.build_DTLN_model_stateful(norm_stft=norm_stft)\n",
    "        # load weights\n",
    "        self.model.load_weights(weights_file)\n",
    "        \n",
    "        #### Model 1 ##########################\n",
    "        farend_mag = Input(batch_shape=(1, 1, (self.blockLen//2+1)))\n",
    "        nearend_mag = Input(batch_shape=(1, 1, (self.blockLen//2+1)))\n",
    "        states_in_1 = Input(batch_shape=(1, self.numLayer, self.numUnits, 2))\n",
    "        # normalizing log magnitude stfts to get more robust against level variations\n",
    "        if norm_stft:\n",
    "            farend_mag_norm = InstantLayerNormalization()(tf.math.log(farend_mag + 1e-7))\n",
    "        else:\n",
    "            # behaviour like in the paper\n",
    "            farend_mag_norm = farend_mag\n",
    "        \n",
    "        if norm_stft:\n",
    "            nearend_mag_norm = InstantLayerNormalization()(tf.math.log(nearend_mag + 1e-7))\n",
    "        else:\n",
    "            # behaviour like in the paper\n",
    "            nearend_mag_norm = nearend_mag\n",
    "        \n",
    "        spectra = Concatenate(axis=-1)([nearend_mag_norm,farend_mag_norm])\n",
    "        # predicting mask with separation kernel\n",
    "        mask_1, states_out_1 = self.seperation_kernel_with_states(self.numLayer, (self.blockLen//2+1), spectra, states_in_1)\n",
    "        \n",
    "        model_1 = Model(inputs=[farend_mag, nearend_mag, states_in_1], outputs=[mask_1, states_out_1])\n",
    "        \n",
    "        #### Model 2 ###########################\n",
    "        \n",
    "        estimated_frames_1 = Input(batch_shape=(1, 1, (self.blockLen)))\n",
    "        farend_mag_seg = Input(batch_shape=(1, 1, (self.blockLen)))\n",
    "        states_in_2 = Input(batch_shape=(1, self.numLayer, self.numUnits, 2))\n",
    "        \n",
    "        # encode time domain frames to feature domain\n",
    "        encoded_frames = Conv1D(self.encoder_size,1,strides=1,use_bias=False)(estimated_frames_1)\n",
    "        encoded_frames_ = Conv1D(self.encoder_size,1,strides=1,use_bias=False)(farend_mag_seg)\n",
    "        \n",
    "        # normalize the input to the separation kernel\n",
    "        encoded_frames_norm = InstantLayerNormalization()(encoded_frames)\n",
    "        encoded_frames_norm_ = InstantLayerNormalization()(encoded_frames_)\n",
    "        \n",
    "        feature = Concatenate(axis=-1)([encoded_frames_norm,encoded_frames_norm_])\n",
    "        # predict mask based on the normalized feature frames\n",
    "        mask_2, states_out_2 = self.seperation_kernel_with_states(self.numLayer, \n",
    "                                                    self.encoder_size, \n",
    "                                                    feature, \n",
    "                                                    states_in_2)\n",
    "        # multiply encoded frames with the mask\n",
    "        estimated = Multiply()([encoded_frames, mask_2]) \n",
    "        # decode the frames back to time domain\n",
    "        decoded_frame = Conv1D(self.blockLen, 1, padding='causal',\n",
    "                               use_bias=False)(estimated)\n",
    "        \n",
    "        model_2 = Model(inputs=[estimated_frames_1, farend_mag_seg, states_in_2], \n",
    "                        outputs=[decoded_frame, states_out_2])\n",
    "        \n",
    "        # set weights to submodels\n",
    "        weights = self.model.get_weights()\n",
    "        print(type(weights))\n",
    "        print(len(weights))\n",
    "        model_1.set_weights(weights[:num_elements_first_core])\n",
    "        model_2.set_weights(weights[num_elements_first_core:])\n",
    "        # convert first model\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model_1)\n",
    "        if use_dynamic_range_quant:\n",
    "            converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite_model = converter.convert()\n",
    "        with tf.io.gfile.GFile(target_name + '_1.tflite', 'wb') as f:\n",
    "              f.write(tflite_model)\n",
    "        # convert second model    \n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model_2)\n",
    "        if use_dynamic_range_quant:\n",
    "            converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite_model = converter.convert()\n",
    "        with tf.io.gfile.GFile(target_name + '_2.tflite', 'wb') as f:\n",
    "              f.write(tflite_model)\n",
    "              \n",
    "        print('TF lite conversion complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0bb36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a02d3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelTrainer = DTLN_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d8fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d407ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder='weights/tflite_weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c64888c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(1, 512)]           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(1, 512)]           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (1, 1, 512)          0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (1, 1, 512)          0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               [(1, 1, 257), (1, 1, 0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               [(1, 1, 257), (1, 1, 0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_5 (TensorFlow [(1, 1, 257)]        0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_4 (TensorFlow [(1, 1, 257)]        0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Log_5 (TensorFlowOp [(1, 1, 257)]        0           tf_op_layer_AddV2_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Log_4 (TensorFlowOp [(1, 1, 257)]        0           tf_op_layer_AddV2_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "instant_layer_normalization_9 ( (1, 1, 257)          514         tf_op_layer_Log_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "instant_layer_normalization_8 ( (1, 1, 257)          514         tf_op_layer_Log_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (1, 1, 514)          0           instant_layer_normalization_9[0][\n",
      "                                                                 instant_layer_normalization_8[0][\n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (1, 1, 128)          329216      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (1, 1, 128)          0           lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (1, 1, 128)          131584      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (1, 1, 257)          33153       lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (1, 1, 257)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (1, 1, 257)          0           lambda_9[0][0]                   \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (1, 1, 512)          0           multiply_3[0][0]                 \n",
      "                                                                 lambda_9[0][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (1, 1, 256)          131072      lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (1, 1, 256)          131072      lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "instant_layer_normalization_10  (1, 1, 256)          512         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "instant_layer_normalization_11  (1, 1, 256)          512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (1, 1, 512)          0           instant_layer_normalization_10[0]\n",
      "                                                                 instant_layer_normalization_11[0]\n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  (1, 1, 128)          328192      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (1, 1, 128)          0           lstm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  (1, 1, 128)          131584      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (1, 1, 256)          33024       lstm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (1, 1, 256)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (1, 1, 256)          0           conv1d_6[0][0]                   \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (1, 1, 512)          131072      multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (1, 512)             0           conv1d_8[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,382,021\n",
      "Trainable params: 1,382,021\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "27\n",
      "TF lite conversion complete!\n"
     ]
    }
   ],
   "source": [
    "modelTrainer.create_tf_lite_model(weights_file, \n",
    "                                  target_folder,\n",
    "                                  norm_stft=True,\n",
    "                                  use_dynamic_range_quant=bool(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f508b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = modelTrainer.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c79a8d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= modelTrainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6b2f1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257,)\n",
      "(257,)\n",
      "(257,)\n",
      "(257,)\n",
      "(514, 512)\n",
      "(128, 512)\n",
      "(512,)\n",
      "(128, 512)\n",
      "(128, 512)\n",
      "(512,)\n",
      "(128, 257)\n",
      "(257,)\n",
      "(1, 512, 256)\n",
      "(1, 512, 256)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(512, 512)\n",
      "(128, 512)\n",
      "(512,)\n",
      "(128, 512)\n",
      "(128, 512)\n",
      "(512,)\n",
      "(128, 256)\n",
      "(256,)\n",
      "(1, 256, 512)\n"
     ]
    }
   ],
   "source": [
    "for i in weights:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75410a15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
