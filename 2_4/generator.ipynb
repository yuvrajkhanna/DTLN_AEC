{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f8af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, fnmatch\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM, Dropout, \\\n",
    "    Lambda, Input, Multiply, Layer, Conv1D, Concatenate\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, CSVLogger, \\\n",
    "    EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import soundfile as sf\n",
    "from wavinfo import WavInfoReader\n",
    "from random import shuffle, seed\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "from utils import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7402421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class audio_generator():\n",
    "    '''\n",
    "    Class to create a Tensorflow dataset based on an iterator from a large scale \n",
    "    audio dataset. This audio generator only supports single channel audio files.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, path_to_nearend_signal, path_to_farend_signal, path_to_rirs, len_of_samples, fs, train_flag=False):\n",
    "        '''\n",
    "        Constructor of the audio generator class.\n",
    "        Inputs:\n",
    "            path_to_input       path to the mixtures\n",
    "            path_to_s1          path to the target source data\n",
    "            len_of_samples      length of audio snippets in samples\n",
    "            fs                  sampling rate\n",
    "            train_flag          flag for activate shuffling of files\n",
    "        '''\n",
    "        # set inputs to properties\n",
    "        self.path_to_nearend_signal = path_to_nearend_signal\n",
    "        self.path_to_farend_signal = path_to_farend_signal\n",
    "        self.path_to_rirs = path_to_rirs\n",
    "        \n",
    "        self.len_of_samples = len_of_samples\n",
    "        self.fs = fs\n",
    "        self.train_flag=train_flag\n",
    "        # count the number of samples in your data set (depending on your disk,\n",
    "        #                                               this can take some time)\n",
    "        #self.count_samples()\n",
    "        # create iterable tf.data.Dataset object\n",
    "        self.create_tf_data_obj()\n",
    "        \n",
    "    def count_samples(self):\n",
    "        '''\n",
    "        Method to list the data of the dataset and count the number of samples. \n",
    "        '''\n",
    "\n",
    "        # list .wav files in directory\n",
    "        self.file_names = fnmatch.filter(os.listdir(self.path_to_nearend_signal), '*.wav')\n",
    "        # count the number of samples contained in the dataset\n",
    "        self.total_samples = 0\n",
    "        for file in self.file_names:\n",
    "            info = WavInfoReader(os.path.join(self.path_to_nearend_signal, file))\n",
    "            self.total_samples = self.total_samples + \\\n",
    "                int(np.fix(info.data.frame_count/self.len_of_samples))\n",
    "    \n",
    "         \n",
    "    def create_generator(self):\n",
    "        '''\n",
    "        Method to create the iterator. \n",
    "        '''\n",
    "        \n",
    "        near_speechs=np.load(self.path_to_nearend_signal)\n",
    "        far_speechs=np.load(self.path_to_farend_signal)\n",
    "        total=min(len(near_speechs),len(far_speechs))\n",
    "        near_speechs=near_speechs[:total]\n",
    "        far_speechs=far_speechs[:total]\n",
    "        rirs=np.load(self.path_to_rirs)\n",
    "        # iterate over the files  \n",
    "        shuffle(near_speechs)\n",
    "        shuffle(far_speechs)\n",
    "        for nearend,farend in zip(near_speechs,far_speechs):\n",
    "            # read the audio files\n",
    "            nearend_signal, fs_1 = sf.read(nearend[:-2])\n",
    "            farend_signal, fs_2 = sf.read(farend[:-2])\n",
    "            nearend_time=int(nearend[-2:])\n",
    "            farend_time=int(farend[-2:])\n",
    "            nearend_signal=nearend_signal[self.len_of_samples*(nearend_time-1):self.len_of_samples*(nearend_time)]\n",
    "            farend_signal=farend_signal[self.len_of_samples*(nearend_time-1):self.len_of_samples*(nearend_time)]\n",
    "            # check if the sampling rates are matching the specifications\n",
    "            if fs_1 != self.fs or fs_2 != self.fs:\n",
    "                raise ValueError('Sampling rates do not match.')\n",
    "            if nearend_signal.ndim != 1 or farend_signal.ndim != 1:\n",
    "                raise ValueError('Too many audio channels. The DTLN audio_generator \\\n",
    "                                 only supports single channel audio data.')\n",
    "            # count the number of samples in one file\n",
    "            num_samples = int(np.fix(nearend_signal.shape[0]/self.len_of_samples))\n",
    "            # iterate over the number of samples\n",
    "            \n",
    "            selected_rirs=np.random.choice(rirs,2)\n",
    "            nearend_rir=sf.read(selected_rirs[0])\n",
    "            farend_rir=sf.read(selected_rirs[1])\n",
    "            input_nearend_signal,input_farend_signal,output_discarded_nearend_speech=preprocess(nearend_signal,farend_signal,nearend_rir,farend_rir,fs)\n",
    "            yield {\"input_1\": input_farend_signal.astype('float32'), \"input_2\": input_nearend_signal.astype('float32')},output_discarded_nearend_speech.astype('float32')\n",
    "              \n",
    "\n",
    "    def create_tf_data_obj(self):\n",
    "        '''\n",
    "        Method to to create the tf.data.Dataset. \n",
    "        '''\n",
    "\n",
    "        # creating the tf.data.Dataset from the iterator\n",
    "        self.tf_data_set = tf.data.Dataset.from_generator(\n",
    "                        self.create_generator,\n",
    "                        output_types=({\"input_1\": tf.float32, \"input_2\": tf.float32}, tf.float32),\n",
    "                        args=None\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ec0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
